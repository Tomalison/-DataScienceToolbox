資料視覺化
資料視覺化將資料用圖表/圖像化的方式表現資料，運用這樣的手法將複雜的資料做簡單的呈現，讓我們對資料有了更多的認識。在 Python 中也有幾個主流的套件可以使用，例如「Matplotlib」、「Seaborn」、「Bokeh」、 「Plotly 」。在 Python 中，有很多種資料視覺化的工具，其中 Matplotlib 與 Seaborn 是最受歡迎的兩個，接下來我們將學習如何使用這兩種工具來進行資料視覺化。

安裝 Matplotlib 與 Seaborn

首先，我們需要安裝 Matplotlib 與 Seaborn。在大多數 Python 發行版中，Matplotlib 與 Seaborn 都已經預先安裝好了，所以你不需要額外安裝。如果你需要安裝 Matplotlib 與 Seaborn，你可以使用 pip 進行安裝，請在終端機輸入以下指令：

pip install matplotlib # 如果在 Colab/Jupyter 環境中安裝使用 !pip install matplotlib 
pip install seaborn # 如果在 Colab/Jupyter 環境中安裝使用 !pip install seaborn 
載入資料

在開始進行資料視覺化之前，我們需要載入一些資料。這裡我們使用 Seaborn 預先提供的 iris 資料集。請在 Python 環境中輸入以下指令：

import seaborn as sns

iris = sns.load_dataset('iris')
iris.head()
這段程式碼會載入 Seaborn 套件，並且使用 sns.load_dataset 函数載入 iris 資料集。接著，我們使用 head() 函数來檢查資料是否載入成功。

使用 Matplotlib 繪製基本圖形
Matplotlib 是 Python 中最常用的資料視覺化工具之一。Matplotlib 可以繪製各種基本圖形，例如散佈圖、線圖和直方圖等。

繪製散佈圖

下面是一個使用 Matplotlib 繪製散佈圖的範例。請複製以下程式碼到 Python 環境中執行：

import matplotlib.pyplot as plt

plt.scatter(iris['sepal_length'], iris['sepal_width'])
plt.xlabel('Sepal Length')
plt.ylabel('Sepal Width')
plt.show()
這段程式碼會繪製出 iris 資料集中 sepal_length 與 sepal_width 兩個變數的散佈圖。我們使用 plt.scatter() 函数來繪製散佈圖，並使用 plt.xlabel() 和 plt.ylabel() 函数來設定 x 軸和 y 軸的標籤。最後，我們使用 plt.show() 函数來顯示圖形。

繪製線圖

下面是一個使用 Matplotlib 繪製線圖的範例。請複製以下程式碼到 Python 環境中執行：

plt.plot(iris['sepal_length'], label='Sepal Length')
plt.plot(iris['sepal_width'], label='Sepal Width')
plt.xlabel('Index')
plt.ylabel('Value')
plt.legend()
plt.show()
這段程式碼會繪製出 iris 資料集中 sepal_length 和 sepal_width 兩個變數的線圖。我們使用 plt.plot() 函数來繪製線圖，並使用 label 參數來指定每條線的標籤。最後，我們使用 plt.legend() 函数來顯示標籤。

繪製直方圖

下面是一個使用 Matplotlib 繪製直方圖的範例。請複製以下程式碼到 Python 環境中執行：

plt.hist(iris['sepal_length'])
plt.xlabel('Sepal Length')
plt.ylabel('Frequency')
plt.show()
這段程式碼會繪製出 iris 資料集中 sepal_length 變數的直方圖。我們使用 plt.hist() 函数來繪製直方圖，並使用 plt.xlabel() 和 plt.ylabel() 函数來設定 x 軸和 y 軸的標籤。

使用 Seaborn 繪製高級圖形
Seaborn 是一個基於 Matplotlib 的 Python 資料視覺化庫。Seaborn 提供了許多高級的圖形和統計分析工具，可以幫助我們更方便地進行資料視覺化和分析。

繪製散佈圖

下面是一個使用 Seaborn 繪製散佈圖的範例。請複製以下程式碼到 Python 環境中執行：

sns.scatterplot(x='sepal_length', y='sepal_width', data=iris)
plt.show()
這段程式碼會繪製出 iris 資料集中 sepal_length 與 sepal_width 兩個變數的散佈圖。我們使用 sns.scatterplot() 函数來繪製散佈圖，並使用 data 參數來指定資料集。

繪製線圖

下面是一個使用 Seaborn 繪製線圖的範例。請複製以下程式碼到 Python 環境中執行：

sns.lineplot(data=iris[['sepal_length', 'sepal_width']])
plt.show()
這段程式碼會繪製出 iris 資料集中 sepal_length 和 sepal_width 兩個變數的線圖。我們使用 sns.lineplot() 函数來繪製線圖，並使用 data 參數來指定資料集。在這個範例中，我們使用了 iris[['sepal_length', 'sepal_width']] 來選擇這兩個變數，並將它們轉換成一個新的 DataFrame。

繪製直方圖

下面是一個使用 Seaborn 繪製直方圖的範例。請複製以下程式碼到 Python 環境中執行：

sns.histplot(data=iris, x='sepal_length')
plt.show()
這段程式碼會繪製出 iris 資料集中 sepal_length 變數的直方圖。我們使用 sns.histplot() 函数來繪製直方圖，並使用 data 參數來指定資料集，使用 x 參數來指定要繪製直方圖的變數。

資料視覺化的延伸閱讀
Matplotlib 和 Seaborn 都是 Python 中常用的資料視覺化庫，它們提供了許多不同種類的圖形和工具，可以幫助我們更方便地進行資料視覺化和分析。Matplotlib 是 Python 中圖表的核心套件，Seaborn 是基於 Matplotlib 更漂亮的套件。Bokeh 和 Plotly 則提供動態的圖表，讓圖表可以以網頁的方式做動態的呈現。但 Matplotlib 的內容相當多且繁瑣，我們不建議花太多時間細看，建議可以從「範例」做學習與參考。以下挑選幾篇延伸閱讀的內容提供深入研究：

深入淺出 Python 視覺化工具 matplotlib、Seaborn 的基礎與架構全指南與教學 ← 必修教材
Matplotlib - Examples ← 必修教材
Matplotlib - Tutorials ← 選修內容
Seaborn - Example gallery ← 必修教材
Seaborn - User guide and tutorial ← 選修內容
特徵工程
特徵工程就是一個把原始數據轉變成特徵的過程，這些特徵可以很好的描述這些數據，並且利用它們建立的模型在未知數據上的表現性能可以達到最優（或者接近最佳性能）。

Feature engineering is manually designing what the input x’s should be. You have to turn your inputs into things the algorithm can understand.
一般來說，機器學習專案的優化有兩個角度：「更厲害的模型」跟「更好用的資料」。所謂的特徵工程就是從「更好用的資料」作為目的。在資料科學中有一句話是「數據和特徵決定了機器學習的上限，模型和算法只是逼近這個上限而已」，其中就強調了特徵的重要性。

為了幫助你可以更好的理解特徵工程，在開始實作前先挑選了幾個入門文件請你快速閱讀：

机器学习之特征工程 ← 必修教材
Feature Engineering ← 必修教材
一文读懂特征工程 ← 選修內容
Python机器学习笔记：使用sklearn做特征工程和数据挖掘 ← 選修內容
特徵工程的常見手法
特徵工程是機器學習中非常重要的一個步驟，它是指對原始數據進行轉換和處理，以提取出對機器學習模型有意義的特徵，常見的方法包括異常值檢測、特徵轉換、特徵縮放、特徵表示、特徵選擇和特徵提取。Python 中的 Pandas 或 Scikit-Learn 套件都提供了一些特徵工程的方法，接下來我們會示範如何利用這些套件進行實作。

異常值檢測

異常值（outliers）是指與其它數據點相比，數值明顯偏離常態分佈的數據點。異常值可能會對機器學習模型的訓練和預測產生不良影響。因此，異常值檢測是特徵工程中的一個重要步驟。

在 Python 中，我們可以使用一些統計方法來檢測異常值。例如，我們可以使用 Z 分數來計算一個數據點的偏差程度。如果某個數據點的 Z 分數大於一個給定閾值，則可以將其視為異常值。以下是一個使用 Z 分數檢測異常值的例子：

import numpy as np

# 創建一個隨機數組
data = np.random.randn(100)

# 計算每個數據點的 Z 分數
z_scores = (data - np.mean(data)) / np.std(data)

# 設置閾值
threshold = 3

# 找到所有 Z 分數大於閾值的數據點
outliers = np.where(np.abs(z_scores) > threshold)[0]

print(outliers)
在這個例子中，我們首先創建了一個包含 100 個隨機數的數組。然後，我們計算了每個數據點的 Z 分數，並設置一個閾值。最後，我們找到了所有 Z 分數大於閾值的數據點的索引。

特徵轉換

特徵轉換是特徵工程的一部分，旨在將原始數據轉換為機器學習模型可以更好理解的格式。特徵轉換中的一種方法是裝箱法，也稱為離散化。裝箱法通常用於數值特徵，它將一組連續值劃分為幾個離散區間（也稱為箱子）。裝箱法有許多好處，包括降低計算成本和增加對離群值的魯棒性。此外，裝箱法還可以幫助解決過擬合問題，因為它可以減少特徵的數量，從而減少模型的複雜度。以下是一些常用的方法：

等寬劃分：將特徵值劃分為等寬區間。例如，如果我們有一個特徵，其值範圍從0到100，我們可以將其劃分為10個等寬區間，每個區間的寬度為10。
等頻劃分：將特徵值劃分為等頻區間。例如，如果我們有一個特徵，其值範圍從0到100，我們可以將其劃分為10個等頻區間，每個區間中包含相同數量的特徵值。
自定義劃分：根據特定需求和背景知識，自行定義劃分區間。
以下是一個簡單的例子示範如何使用 Pandas 的 cut 函數：

import pandas as pd

# 創建一個包含5個數字的 DataFrame
df = pd.DataFrame({'numbers': [1, 7, 15, 23, 33]})

# 使用 cut 函數劃分為2個等寬區間
df['bins'] = pd.cut(df['numbers'], bins=2)

# 查看結果
print(df)
以上的程式碼會輸出以下結果：

   numbers        bins
0        1  (0.975, 17.0]
1        7  (0.975, 17.0]
2       15  (0.975, 17.0]
3       23   (17.0, 32.0]
4       33   (17.0, 32.0]
接下來我們將使用 pandas 中的 qcut() 函數進行裝箱。 qcut() 函數可以將資料分成幾個相等大小的箱子，每個箱子中包含的觀測值數量相同。以下例子我們將 'Age' 這個特徵使用 qcut() 函數進行了裝箱。參數 q 設置為 4，意味著將 'Age' 特徵分成四個箱子。labels=False 表示生成的箱子標籤為數值。

import pandas as pd

# 創建一個包含 Missing Value 的 DataFrame
df = pd.DataFrame({'Age': [22, 38, 26, 35, 35, np.nan, 54, 2, 27, 14]})

# 使用 qcut 函數將數值型特徵轉換成等頻分箱
df['Age_binned'] = pd.qcut(df['Age'], q=4, labels=False)

print(df[['Age', 'Age_binned']].head(10))
以上的程式碼會輸出以下結果：

    Age  Age_binned
0  22.0          0
1  38.0          3
2  26.0          1
3  35.0          3
4  35.0          3
5   NaN          NaN
6  54.0          3
7   2.0          0
8  27.0          1
9  14.0          0
我們可以看到 'Age' 特徵已經被轉換成了 'Age_binned'，並且每個箱子中包含的觀測值數量相同。

特徵縮放

特徵縮放是指將數據縮放到一個固定的範圍內，以使所有特徵具有相同的重要性。特徵縮放通常用於需要計算距離的機器學習算法中，例如 k-最近鄰（k-nearest neighbors，KNN）和支持向量機（support vector machine，SVM）。以下是一些常見的特徵縮放方法：

最小-最大縮放（min-max scaling）：將數據縮放到 0 到 1 之間。
Z-score 縮放：將數據縮放為標準正態分佈。
正則化（normalization）：將數據縮放為單位長度。
以下是一個使用 Scikit-learn 進行特徵縮放的例子：

from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import Normalizer
import numpy as np

# 創建一個隨機數組
data = np.random.randn(100, 2)

# 最小-最大縮放
scaler_minmax = MinMaxScaler()
data_minmax = scaler_minmax.fit_transform(data)

# Z-score 縮放
scaler_zscore = StandardScaler()
data_zscore = scaler_zscore.fit_transform(data)

正則化
scaler_norm = Normalizer()
data_norm = scaler_norm.fit_transform(data)

print(data_minmax.shape)
print(data_zscore.shape)
print(data_norm.shape)
在這個例子中，我們首先創建了一個包含 100 個隨機數的二維數組。然後，我們使用 Scikit-learn 中的 MinMaxScaler 進行最小-最大縮放，使用 StandardScaler 進行 Z-score 縮放，以及使用 Normalizer 進行正則化。

特徵選擇

特徵選擇是指從原始數據中選擇最具有信息量的特徵，以用於訓練機器學習模型。選擇更好的特徵可以提高模型的準確性，同時降低過擬合和計算成本。以下是一些常見的特徵選擇方法：

過濾法（Filter method）：根據某些統計量或模型評估指標，對原始特徵進行評分，然後選擇評分最高的特徵。
包裝法（Wrapper method）：通過訓練模型，反復地選擇特徵，直到達到某個指定的準確度或特徵數量。
嵌入法（Embedded method）：在訓練過程中，利用正則化等技術將特徵的權重進行約束，從而實現特徵選擇。
以下是一個使用 Scikit-learn 進行特徵選擇的例子：

from sklearn.datasets import load_boston
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_regression

# 加載波士頓房價數據集
boston = load_boston()
X, y = boston.data, boston.target

# 過濾法特徵選擇
selector = SelectKBest(f_regression, k=5)
X_new = selector.fit_transform(X, y)

print(X_new.shape)
在這個例子中，我們首先使用 Scikit-learn 中的 load_boston 函數加載波士頓房價數據集。然後，我們使用 SelectKBest 和 f_regression 進行過濾法特徵選擇，選擇得分最高的 5 個特徵。

特徵工程是機器學習中非常重要的一個步驟，可以大大提高模型的性能。在這篇文章中，我們介紹了常見的特徵工程方法，包括異常值檢測、特徵轉換、特徵縮放、特徵選擇。不過在實際上特徵工程還有各式各樣的技巧與手法，我們不建議在初學階段就花太多時間研究，而是在未來的實作過程中持續地觀摩與練習。

